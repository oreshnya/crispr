{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорт библиотек и загрузка файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import (mean_squared_error, mean_absolute_error, confusion_matrix,\n",
    "                            precision_score, recall_score, f1_score, fbeta_score)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout, BatchNormalization, Input, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from modules.utils import download_data, txt_to_df\n",
    "from modules.data_transformation import *\n",
    "from modules.db_manager import (\n",
    "    connect_db,\n",
    "    load_df_to_db,\n",
    "    table_to_dataframe,\n",
    "    close_db,\n",
    "    create_clean_table,\n",
    "    insert_clean_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сейчас не нужно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"data/K562.txt\", sep=\",\", engine=\"python\",\n",
    "#                  names=['target', 'potential_off_target', 'is_off_target']\n",
    "#                  )\n",
    "\n",
    "# df['encoded_7channels'] = df.apply(\n",
    "#     lambda row: encode_7channels(\n",
    "#         row['target'],\n",
    "#         row['potential_off_target'],\n",
    "#         pam_location=\"last\",\n",
    "#         pam_length=3\n",
    "#     ).flatten(),\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# df['mismatch_count'] = df.apply(\n",
    "#     lambda row: count_mismatches(row['target'], row['potential_off_target']),\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# df['gc_target'] = df['target'].apply(calc_gc_content)\n",
    "# df['gc_off_target'] = df['potential_off_target'].apply(calc_gc_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Объединяем данные из эксель файла в один датафрейм, добавляя столбец cell_line (название листа в файле)\n",
    "# file_path=\"data/4_cell_lines.xlsx\"\n",
    "# sheets = pd.ExcelFile(file_path).sheet_names\n",
    "\n",
    "# df_list = []\n",
    "\n",
    "# for sheet in sheets:\n",
    "#     df = pd.read_excel(file_path, sheet_name=sheet)\n",
    "#     df[\"cell_line\"] = sheet\n",
    "#     df_list.append(df)\n",
    "\n",
    "# final_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# print(final_df.head())\n",
    "\n",
    "# final_df.to_csv(\"data/4_cell_lines.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"data/Table_S8_machine_learning_input.csv\", sep=\"\\t\", engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.read_csv(\"data/HEK293t.txt\", sep=\",\", engine=\"python\")\n",
    "# df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Начало"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_csv(r\"data/II4.txt\", sep=\",\", engine=\"python\", names=['target', 'potential_off_target', 'is_off_target'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"data/K562_with_extra_features.csv\", sep=\",\", engine=\"python\")\n",
    "df.drop(columns=df.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mismatch_count\n",
       "6    16070\n",
       "5     3547\n",
       "4      608\n",
       "3       76\n",
       "2       13\n",
       "1        4\n",
       "7        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mismatch_count.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mismatch_count\n",
       "4    71\n",
       "3    32\n",
       "2    12\n",
       "1     4\n",
       "7     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.is_off_target == 1].mismatch_count.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(r\"data/4_cell_lines.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Генерируем эмбеддинги для target\n",
    "# target_embeddings = generate_embeddings_v3(df, sequence_column='target', polymer_type='DNA', encoding_strategy='aptamer')\n",
    "# target_embeddings.to_csv(r'data/target_embeddings.csv', header=True)\n",
    "\n",
    "# # Генерируем эмбеддинги для potential_off_target\n",
    "# off_target_embeddings = generate_embeddings_v3(df, sequence_column='potential_off_target',\n",
    "#                                                polymer_type='DNA', encoding_strategy='aptamer')\n",
    "# off_target_embeddings.to_csv(r'data/off_target_embeddings.csv', header=True)\n",
    "\n",
    "# # Объединяем с исходным DataFrame\n",
    "# df = df.join(target_embeddings.add_prefix('target_'), how='left')\n",
    "# df = df.join(off_target_embeddings.add_prefix('off_target_'), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_embeddings = pd.read_csv(\"data/target_embeddings.csv\", index_col=0)\n",
    "off_target_embeddings = pd.read_csv(\"data/off_target_embeddings.csv\", index_col=0)\n",
    "\n",
    "df = df.join(target_embeddings.add_prefix('target_'), how='left')\n",
    "df = df.join(off_target_embeddings.add_prefix('off_target_'), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер после очистки: (20319, 93)\n",
      "X_target_train shape: (16255, 43)\n",
      "X_off_train shape: (16255, 43)\n",
      "y_train shape: (16255,)\n"
     ]
    }
   ],
   "source": [
    "# Удаляем строки, где нет хотя бы одного эмбеддинга\n",
    "df_cleaned = df.dropna(subset=[f'target_feature_{i}' for i in range(43)] + \n",
    "                               [f'off_target_feature_{i}' for i in range(43)]).reset_index(drop=True)\n",
    "\n",
    "print(f\"Размер после очистки: {df_cleaned.shape}\")  # Должно быть (20319, 93), если всё норм\n",
    "\n",
    "target_features = [f'target_feature_{i}' for i in range(43)]\n",
    "off_target_features = [f'off_target_feature_{i}' for i in range(43)]\n",
    "\n",
    "X_target = df_cleaned[target_features].to_numpy()\n",
    "X_off_target = df_cleaned[off_target_features].to_numpy()\n",
    "y = df_cleaned['is_off_target'].fillna(0).to_numpy()\n",
    "\n",
    "# Разделяем данные\n",
    "X_target_train, X_target_test, X_off_train, X_off_test, y_train, y_test = train_test_split(\n",
    "    X_target, X_off_target, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"X_target_train shape: {X_target_train.shape}\")\n",
    "print(f\"X_off_train shape: {X_off_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ target_input        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ off_target_input    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,816</span> │ target_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,816</span> │ off_target_input… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dropout_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_18          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ target_input        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ off_target_input    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m2,816\u001b[0m │ target_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m2,816\u001b[0m │ off_target_input… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_17          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dropout_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dropout_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,512\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_18          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_19          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,465</span> (119.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m30,465\u001b[0m (119.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,465</span> (119.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30,465\u001b[0m (119.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Вход для target\n",
    "input_target = Input(shape=(43,), name='target_input')\n",
    "\n",
    "# Вход для potential_off_target\n",
    "input_off_target = Input(shape=(43,), name='off_target_input')\n",
    "\n",
    "# Полносвязные слои для target\n",
    "x1 = Dense(64, activation='relu')(input_target)\n",
    "x1 = Dropout(0.3)(x1)\n",
    "\n",
    "# Полносвязные слои для potential_off_target\n",
    "x2 = Dense(64, activation='relu')(input_off_target)\n",
    "x2 = Dropout(0.3)(x2)\n",
    "\n",
    "# Объединяем два входа\n",
    "merged = Concatenate()([x1, x2])\n",
    "x = Dense(128, activation='relu')(merged)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# Выходной слой (теперь он правильно связан с моделью)\n",
    "output = Dense(1, activation='sigmoid', name='output')(x)\n",
    "\n",
    "# Определяем модель\n",
    "model = Model(inputs=[input_target, input_off_target], outputs=output)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Вывод структуры модели\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: np.float64(0.502970480846587), 1: np.float64(84.66145833333333)}\n",
      "Epoch 1/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.7464 - loss: 5.6945 - val_accuracy: 0.0920 - val_loss: 0.8014\n",
      "Epoch 2/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.5471 - loss: 1.1978 - val_accuracy: 0.9945 - val_loss: 0.3656\n",
      "Epoch 3/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.5855 - loss: 1.1828 - val_accuracy: 0.0584 - val_loss: 0.8825\n",
      "Epoch 4/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.2962 - loss: 0.7089 - val_accuracy: 0.0821 - val_loss: 0.7433\n",
      "Epoch 5/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3202 - loss: 0.8664 - val_accuracy: 0.9923 - val_loss: 0.6414\n",
      "Epoch 6/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3410 - loss: 0.6513 - val_accuracy: 0.0892 - val_loss: 0.7275\n",
      "Epoch 7/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1937 - loss: 0.7016 - val_accuracy: 0.0806 - val_loss: 0.6997\n",
      "Epoch 8/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2673 - loss: 0.6761 - val_accuracy: 0.0997 - val_loss: 0.6973\n",
      "Epoch 9/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3443 - loss: 0.7534 - val_accuracy: 0.0615 - val_loss: 0.7320\n",
      "Epoch 10/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4100 - loss: 0.7270 - val_accuracy: 0.0729 - val_loss: 0.7344\n",
      "Epoch 11/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2293 - loss: 0.7791 - val_accuracy: 0.9945 - val_loss: 0.5755\n",
      "Epoch 12/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6267 - loss: 0.6134 - val_accuracy: 0.0726 - val_loss: 0.7487\n",
      "Epoch 13/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1230 - loss: 0.7166 - val_accuracy: 0.0950 - val_loss: 0.7109\n",
      "Epoch 14/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2722 - loss: 0.7010 - val_accuracy: 0.0615 - val_loss: 0.7478\n",
      "Epoch 15/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1356 - loss: 0.6941 - val_accuracy: 0.0055 - val_loss: 0.7763\n",
      "Epoch 16/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2163 - loss: 0.6807 - val_accuracy: 0.0707 - val_loss: 0.7299\n",
      "Epoch 17/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1837 - loss: 0.6868 - val_accuracy: 0.0901 - val_loss: 0.7192\n",
      "Epoch 18/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3991 - loss: 0.6432 - val_accuracy: 0.1098 - val_loss: 0.7108\n",
      "Epoch 19/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4289 - loss: 0.7343 - val_accuracy: 0.0711 - val_loss: 0.7508\n",
      "Epoch 20/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3002 - loss: 0.6628 - val_accuracy: 0.0898 - val_loss: 0.7382\n"
     ]
    }
   ],
   "source": [
    "# Преобразуем список классов в numpy массив\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.array([0, 1]), y=y_train)\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "print(f\"Class Weights: {class_weight_dict}\")  # Посмотрим, какие веса\n",
    "\n",
    "# Обучаем с учетом весов\n",
    "history = model.fit(\n",
    "    [X_target_train, X_off_train], y_train, \n",
    "    epochs=20, batch_size=32, validation_split=0.2, \n",
    "    class_weight=class_weight_dict, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0813 - loss: 0.7434\n",
      "Test Loss: 0.74396\n",
      "Test Accuracy: 0.07899\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\n",
      "Metrics:\n",
      "Precision: 0.00635\n",
      "Recall: 1.00000\n",
      "F1-score: 0.01263\n",
      "F-beta (1): 0.01263\n",
      "Threshold used: 0.4\n",
      "\n",
      "Results DataFrame (first 5 rows):\n",
      "   y_test  y_pred_proba  y_pred prediction_is_true\n",
      "0       0      0.551689       1                 No\n",
      "1       0      0.551689       1                 No\n",
      "2       0      0.551689       1                 No\n",
      "3       0      0.551689       1                 No\n",
      "4       0      0.551689       1                 No\n",
      "\n",
      "Annotated Confusion Matrix:\n",
      "                       Predicted No (0)          Predicted Yes (1)\n",
      "Actual No (0)   TN (True Negative): 287  FP (False Positive): 3753\n",
      "Actual Yes (1)   FN (False Negative): 0     TP (True Positive): 24\n"
     ]
    }
   ],
   "source": [
    "results_df, annotated_cm = evaluate_model(model, [X_target_test, X_off_test], y_test, beta=1, threshold=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoded_7channels + 3 extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Входы\n",
    "sequence_input = Input(shape=(23, 7), name='sequence_input')  # N = длина последовательности\n",
    "additional_input = Input(shape=(3,), name='additional_input')  # gc_content, mismatch_count\n",
    "\n",
    "# CNN для последовательностей\n",
    "x = Conv1D(32, kernel_size=3, activation='relu')(sequence_input)\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Полносвязный слой для дополнительных признаков\n",
    "w = Dense(16, activation='relu')(additional_input)\n",
    "\n",
    "# Объединяем\n",
    "combined = Concatenate()([x, w])\n",
    "z = Dense(64, activation='relu')(combined)\n",
    "output = Dense(1, activation='sigmoid')(z)\n",
    "\n",
    "# Финальная модель\n",
    "model = tf.keras.Model(inputs=[sequence_input, additional_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0044 - val_accuracy: 0.9975 - val_loss: 0.0131\n",
      "Epoch 2/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 0.9982 - val_loss: 0.0054\n",
      "Epoch 3/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.4825e-04 - val_accuracy: 0.9988 - val_loss: 0.0073\n",
      "Epoch 4/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.2149e-05 - val_accuracy: 0.9978 - val_loss: 0.0092\n",
      "Epoch 5/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.4437e-05 - val_accuracy: 0.9978 - val_loss: 0.0090\n",
      "Epoch 6/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.3947e-05 - val_accuracy: 0.9978 - val_loss: 0.0100\n",
      "Epoch 7/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.1514e-05 - val_accuracy: 0.9978 - val_loss: 0.0098\n",
      "Epoch 8/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.3088e-05 - val_accuracy: 0.9978 - val_loss: 0.0093\n",
      "Epoch 9/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9409e-05 - val_accuracy: 0.9978 - val_loss: 0.0098\n",
      "Epoch 10/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.0444e-05 - val_accuracy: 0.9978 - val_loss: 0.0097\n",
      "Epoch 11/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5852e-05 - val_accuracy: 0.9978 - val_loss: 0.0095\n",
      "Epoch 12/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0744e-05 - val_accuracy: 0.9978 - val_loss: 0.0108\n",
      "Epoch 13/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.9556e-06 - val_accuracy: 0.9978 - val_loss: 0.0098\n",
      "Epoch 14/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.8496e-06 - val_accuracy: 0.9975 - val_loss: 0.0115\n",
      "Epoch 15/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.6149e-06 - val_accuracy: 0.9978 - val_loss: 0.0109\n",
      "Epoch 16/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.4966e-06 - val_accuracy: 0.9975 - val_loss: 0.0115\n",
      "Epoch 17/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.9172e-06 - val_accuracy: 0.9972 - val_loss: 0.0113\n",
      "Epoch 18/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.6765e-06 - val_accuracy: 0.9982 - val_loss: 0.0102\n",
      "Epoch 19/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.3720e-06 - val_accuracy: 0.9972 - val_loss: 0.0119\n",
      "Epoch 20/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.0357e-06 - val_accuracy: 0.9972 - val_loss: 0.0121\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.0038\n",
      "Test Loss: 0.00235\n",
      "Test Accuracy: 0.99926\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Results DataFrame (first 5 rows):\n",
      "   y_test  y_pred prediction_is_true\n",
      "0       0       0                Yes\n",
      "1       0       0                Yes\n",
      "2       0       0                Yes\n",
      "3       0       0                Yes\n",
      "4       0       0                Yes\n",
      "\n",
      "Annotated Confusion Matrix:\n",
      "                        Predicted No (0)       Predicted Yes (1)\n",
      "Actual No (0)   TN (True Negative): 4040  FP (False Positive): 0\n",
      "Actual Yes (1)    FN (False Negative): 3  TP (True Positive): 21\n"
     ]
    }
   ],
   "source": [
    "X_seq_train, X_seq_test, X_add_train, X_add_test, y_train, y_test = train_test_split(\n",
    "    X_sequences, X_additional, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Обучение модели на тренировочных данных\n",
    "model.fit(\n",
    "    [X_seq_train, X_add_train],\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.0038\n",
      "Test Loss: 0.00235\n",
      "Test Accuracy: 0.99926\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Results DataFrame (first 5 rows):\n",
      "   y_test  y_pred prediction_is_true\n",
      "0       0       0                Yes\n",
      "1       0       0                Yes\n",
      "2       0       0                Yes\n",
      "3       0       0                Yes\n",
      "4       0       0                Yes\n",
      "\n",
      "Annotated Confusion Matrix:\n",
      "                        Predicted No (0)       Predicted Yes (1)\n",
      "Actual No (0)   TN (True Negative): 4040  FP (False Positive): 0\n",
      "Actual Yes (1)    FN (False Negative): 3  TP (True Positive): 21\n"
     ]
    }
   ],
   "source": [
    "# Оценка модели на тестовых данных\n",
    "results_df, annotated_cm = evaluate_model(model, [X_seq_test, X_add_test], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only encoded_7channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем данные\n",
    "X = np.array([np.reshape(ch, (7, -1)).T for ch in df['encoded_7channels']])  # Преобразуем flattened массивы обратно в матрицы 7xN\n",
    "y = np.array(df['is_off_target'])  # Бинарная целевая переменная\n",
    "\n",
    "# Разделение на тренировочный и тестовый наборы\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Определяем параметры входа\n",
    "input_shape = X_train.shape[1:]  # (длина последовательности, 7 каналов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Values: [0 1]\n",
      "Frequency Values: [4040   24]\n"
     ]
    }
   ],
   "source": [
    "unique, frequency = np.unique(y_test, return_counts = True)\n",
    "\n",
    "print(\"Unique Values:\", unique)\n",
    "print(\"Frequency Values:\", frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\polina\\CRISPR\\crispr\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9826 - loss: 0.0606 - val_accuracy: 0.9938 - val_loss: 0.0313\n",
      "Epoch 2/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9953 - loss: 0.0146 - val_accuracy: 0.9945 - val_loss: 0.0147\n",
      "Epoch 3/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9962 - loss: 0.0099 - val_accuracy: 0.9942 - val_loss: 0.0174\n",
      "Epoch 4/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9971 - loss: 0.0082 - val_accuracy: 0.9945 - val_loss: 0.0149\n",
      "Epoch 5/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9973 - loss: 0.0065 - val_accuracy: 0.9945 - val_loss: 0.0142\n",
      "Epoch 6/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9975 - loss: 0.0068 - val_accuracy: 0.9938 - val_loss: 0.0148\n",
      "Epoch 7/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0064 - val_accuracy: 0.9945 - val_loss: 0.0151\n",
      "Epoch 8/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0081 - val_accuracy: 0.9945 - val_loss: 0.0134\n",
      "Epoch 9/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0044 - val_accuracy: 0.9942 - val_loss: 0.0138\n",
      "Epoch 10/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9980 - loss: 0.0056 - val_accuracy: 0.9951 - val_loss: 0.0142\n",
      "Epoch 11/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9983 - loss: 0.0049 - val_accuracy: 0.9920 - val_loss: 0.0210\n",
      "Epoch 12/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9973 - loss: 0.0062 - val_accuracy: 0.9954 - val_loss: 0.0196\n",
      "Epoch 13/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0050 - val_accuracy: 0.9951 - val_loss: 0.0184\n",
      "Epoch 14/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0022 - val_accuracy: 0.9920 - val_loss: 0.0276\n",
      "Epoch 15/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0037 - val_accuracy: 0.9942 - val_loss: 0.0277\n",
      "Epoch 16/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9978 - loss: 0.0056 - val_accuracy: 0.9935 - val_loss: 0.0171\n",
      "Epoch 17/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9988 - loss: 0.0027 - val_accuracy: 0.9926 - val_loss: 0.0229\n",
      "Epoch 18/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9983 - loss: 0.0042 - val_accuracy: 0.9935 - val_loss: 0.0257\n",
      "Epoch 19/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9989 - loss: 0.0023 - val_accuracy: 0.9935 - val_loss: 0.0237\n",
      "Epoch 20/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9979 - loss: 0.0049 - val_accuracy: 0.9948 - val_loss: 0.0211\n"
     ]
    }
   ],
   "source": [
    "# Создаем модель CNN\n",
    "model = Sequential([\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')  # Для бинарной классификации\n",
    "])\n",
    "\n",
    "# Компилируем модель\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Обучаем модель\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted No (0)</th>\n",
       "      <th>Predicted Yes (1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual No (0)</th>\n",
       "      <td>TN (True Negative): 4035</td>\n",
       "      <td>FP (False Positive): 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Yes (1)</th>\n",
       "      <td>FN (False Negative): 5</td>\n",
       "      <td>TP (True Positive): 19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Predicted No (0)       Predicted Yes (1)\n",
       "Actual No (0)   TN (True Negative): 4035  FP (False Positive): 5\n",
       "Actual Yes (1)    FN (False Negative): 5  TP (True Positive): 19"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df, annotated_cm = evaluate_model(model, [X_seq_test, X_add_test], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно свести к минимуму FN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings_v3(df, sequence_column, polymer_type='DNA', encoding_strategy='aptamer', batch_size=80):\n",
    "    \"\"\"\n",
    "    Генерирует эмбеддинги для последовательностей из указанного столбца DataFrame.\n",
    "    Сохраняет индексы для последующего объединения.\n",
    "\n",
    "    :param df: Исходный DataFrame с последовательностями.\n",
    "    :param sequence_column: Название столбца с последовательностями.\n",
    "    :param polymer_type: Тип полимера ('DNA' для последовательностей ATGC).\n",
    "    :param encoding_strategy: Стратегия кодирования ('aptamer').\n",
    "    :param batch_size: Количество последовательностей в одном запросе.\n",
    "    :return: DataFrame с эмбеддингами, индексами, совпадающими с исходным DataFrame.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        'accept': 'application/json',\n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    "\n",
    "    # Исходные последовательности + сохранение их индексов\n",
    "    sequences = df[sequence_column].tolist()\n",
    "    indices = df.index.tolist()  # Сохраняем индексы для правильного присоединения\n",
    "\n",
    "    # Разбиваем на батчи по 80 последовательностей\n",
    "    several_id_lists = np.array_split(np.asarray(sequences), int(len(sequences) / batch_size) + 1)\n",
    "    index_splits = np.array_split(np.asarray(indices), int(len(sequences) / batch_size) + 1)\n",
    "\n",
    "    embeddings = {}\n",
    "\n",
    "    for i, (batch, index_batch) in enumerate(zip(several_id_lists, index_splits)):\n",
    "        print(f\"Обрабатываем батч {i + 1} из {len(several_id_lists)}...\")\n",
    "        params = {\n",
    "            'sequences': ', '.join(list(batch)),\n",
    "            'polymer_type': polymer_type,\n",
    "            'encoding_strategy': encoding_strategy,\n",
    "            'skip_unprocessable': 'true',\n",
    "        }\n",
    "        try:\n",
    "            # Отправляем запрос\n",
    "            response = requests.post('https://ai-chemistry.itmo.ru/api/encode_sequence', params=params, headers=headers)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            # Преобразуем ответ в JSON\n",
    "            data = json.loads(response.content)\n",
    "            \n",
    "            # Записываем эмбеддинги в словарь с сохранением индексов\n",
    "            for seq, idx in zip(batch, index_batch):\n",
    "                if seq in data:\n",
    "                    embeddings[idx] = data[seq]\n",
    "                else:\n",
    "                    embeddings[idx] = None  # Если последовательность не обработалась, ставим None\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Ошибка при обработке батча {i + 1}: {e}\")\n",
    "\n",
    "        # Задержка для предотвращения перегрузки API\n",
    "        time.sleep(4)\n",
    "\n",
    "    # Преобразуем словарь в DataFrame\n",
    "    embeddings_df = pd.DataFrame.from_dict(embeddings, orient='index')\n",
    "\n",
    "    # Добавляем имена столбцов\n",
    "    embeddings_df.columns = [f\"feature_{i}\" for i in range(embeddings_df.shape[1])]\n",
    "\n",
    "    # Убеждаемся, что индексы соответствуют исходному DataFrame\n",
    "    embeddings_df = embeddings_df.reindex(df.index)\n",
    "\n",
    "    return embeddings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, beta=2, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Оценивает Keras модель и выводит результаты: accuracy, confusion matrix, precision, recall, F1-score и F-beta score.\n",
    "\n",
    "    :param model: Keras Model\n",
    "    :param X_test: Тестовые данные (массив или список массивов для многовходных моделей)\n",
    "    :param y_test: Истинные значения\n",
    "    :param beta: Значение beta для F-beta score (по умолчанию 2)\n",
    "    :param threshold: Порог классификации (по умолчанию 0.5)\n",
    "    :return: Tuple (results_df, annotated_cm)\n",
    "    \"\"\"\n",
    "    # Проверка размерностей данных\n",
    "    if isinstance(X_test, list):\n",
    "        for i, x in enumerate(X_test):\n",
    "            if len(x) != len(y_test):\n",
    "                raise ValueError(\n",
    "                    f\"Размер входного массива X_test[{i}] ({len(x)}) не совпадает с размером y_test ({len(y_test)}).\"\n",
    "                )\n",
    "    else:\n",
    "        if len(X_test) != len(y_test):\n",
    "            raise ValueError(\n",
    "                f\"Размер входного массива X_test ({len(X_test)}) не совпадает с размером y_test ({len(y_test)}).\"\n",
    "            )\n",
    "\n",
    "    # Оцениваем модель\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(f\"Test Loss: {test_loss:.5f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.5f}\")\n",
    "\n",
    "    # Предсказания вероятностей\n",
    "    y_pred_proba = model.predict(X_test)\n",
    "\n",
    "    # Применяем порог классификации\n",
    "    y_pred = (y_pred_proba > threshold).astype(int).flatten()\n",
    "\n",
    "    # Вычисление метрик\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    f_beta = fbeta_score(y_test, y_pred, beta=beta, zero_division=0)\n",
    "\n",
    "    print(\"\\nMetrics:\")\n",
    "    print(f\"Precision: {precision:.5f}\")\n",
    "    print(f\"Recall: {recall:.5f}\")\n",
    "    print(f\"F1-score: {f1:.5f}\")\n",
    "    print(f\"F-beta ({beta}): {f_beta:.5f}\")\n",
    "    print(f\"Threshold used: {threshold}\")\n",
    "\n",
    "    # Создаем DataFrame с результатами\n",
    "    results_df = pd.DataFrame({\n",
    "        'y_test': y_test,\n",
    "        'y_pred_proba': y_pred_proba.flatten(),  # Добавляем вероятности\n",
    "        'y_pred': y_pred,\n",
    "    })\n",
    "    results_df['prediction_is_true'] = results_df.apply(\n",
    "        lambda row: 'Yes' if row['y_test'] == row['y_pred'] else 'No',\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Выводим первые строки DataFrame\n",
    "    print(\"\\nResults DataFrame (first 5 rows):\")\n",
    "    print(results_df.head())\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm_df = pd.DataFrame(\n",
    "        cm, \n",
    "        index=['Actual No (0)', 'Actual Yes (1)'], \n",
    "        columns=['Predicted No (0)', 'Predicted Yes (1)']\n",
    "    )\n",
    "\n",
    "    # Аннотированная confusion matrix\n",
    "    annotations = [\n",
    "        ['TN (True Negative)', 'FP (False Positive)'],\n",
    "        ['FN (False Negative)', 'TP (True Positive)']\n",
    "    ]\n",
    "    annotated_cm = cm_df.astype(str)\n",
    "    for i, row in enumerate(cm_df.index):\n",
    "        for j, col in enumerate(cm_df.columns):\n",
    "            annotated_cm.loc[row, col] = f\"{annotations[i][j]}: {cm[i, j]}\"\n",
    "\n",
    "    # Выводим annotated confusion matrix\n",
    "    print(\"\\nAnnotated Confusion Matrix:\")\n",
    "    print(annotated_cm)\n",
    "\n",
    "    return results_df, annotated_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(df: pd.DataFrame, encoding_function, model) -> None:\n",
    "    \"\"\"\n",
    "    Обучает модель с использованием заданной функции кодирования и выводит R^2, MSE, предсказания и тестовые значения.\n",
    "\n",
    "    :param df: Датафрейм с колонками genome input, sgRNA input и mean relative gamma\n",
    "    :param encoding_function: Функция кодирования для использования\n",
    "    \"\"\"\n",
    "    # Кодирование данных\n",
    "    df['encoded'] = df.apply(\n",
    "        lambda row: encoding_function(row['genome input'], row['sgRNA input']).flatten(),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Подготовка данных для обучения\n",
    "    X = np.vstack(df['encoded'].values)  # Преобразование списка массивов в 2D массив\n",
    "    y = df['mean relative gamma']\n",
    "\n",
    "    # Разделяем данные на обучающую и тестовую выборки\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Обучение модели\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Предсказания\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Вычисление метрик\n",
    "    r2_score = model.score(X_test, y_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    # Вывод результатов\n",
    "    print(f\"R^2 Score: {r2_score:.4f}\")\n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "    print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "    print(\"Predictions vs Actual:\")\n",
    "    for pred, actual in zip(y_pred, y_test):\n",
    "        print(f\"Predicted: {pred:.4f}, Actual: {actual:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
